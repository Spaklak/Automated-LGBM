### README_RUS.md

# Автоматизированный Пайплайн для Машинного Обучения с использованием LightGBM

Этот проект предоставляет автоматизированный пайплайн для машинного обучения, разработанный для упрощения и ускорения процессов тренировки, настройки и оценки модели LightGBM. Весь процесс – от обработки данных до подбора гиперпараметров и визуализации – реализован в пайплайне `lgbm_pipeline`, что позволяет существенно сократить время разработки и улучшить воспроизводимость. Пайплайн подходит для задач бинарной классификации, требующих высокой эффективности и стабильности.

---

## Оглавление
1. [Описание проекта](#описание-проекта)
2. [Требования](#требования)
3. [Установка](#установка)
4. [Использование](#использование)
5. [Документация по Классу и Методам](#документация-по-классу-и-методам)
6. [Как помочь проекту](#как-помочь-проекту)
7. [Лицензия](#лицензия)

---

### Описание проекта
Пайплайн автоматизирует задачи обработки данных, обучения модели и ее оценки, включая:
- Исследовательский анализ данных с визуализацией распределений и корреляций.
- Автоматическую обработку пропусков и удаление дубликатов.
- Разделение данных на обучающую, валидационную и тестовую выборки.
- Обучение модели и подбор гиперпараметров с помощью `GridSearchCV`.
- Анализ важности признаков с использованием SHAP.
- Оценку стабильности признаков с помощью анализа PSI.
- Выбор признаков с использованием методов RFE и RFECV.
- Сохранение модели для последующего использования в форматах `joblib` и `pickle`.

### Требования
Для работы пайплайна необходимы следующие библиотеки:
- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`
- `shap`
- `lightgbm`
- `scikit-learn`
- `joblib`

### Установка
Склонируйте репозиторий и установите зависимости:
```bash
git clone <repository-url>
cd <repository-directory>
pip install -r requirements.txt
```

### Использование
Класс `ModelPipeline` можно использовать, инициализировав его с путем к набору данных, а затем вызвав необходимые методы для подготовки данных, обучения модели и оценки результатов.

```python
from your_module import ModelPipeline

# Инициализация с путем к набору данных
pipeline = ModelPipeline(path="data.csv")

# Пример использования
pipeline.split_train_val_test(target_col='target')
pipeline.fit_lgbm()
pipeline.evaluate_model()
pipeline.shap_analysis()
pipeline.save_grid_model_pickle(name='final_model.pkl')
```

---

## Документация по Классу и Методам

### `ModelPipeline`
#### `__init__(self, path, **kwargs)`
- Инициализирует пайплайн и загружает набор данных.
  
#### `get_target_distribution(self, target_col)`
- **Описание**: Возвращает процентное распределение классов для указанного целевого столбца.
  
#### `misiing_data_summary(self)`
- **Описание**: Предоставляет сводку пропущенных данных по каждому столбцу.
  
#### `total_missing_data(self)`
- **Описание**: Возвращает общее количество пропущенных значений в наборе данных.
  
#### `plot_correlation_matrix(self, method='spearman', numeric_only=True, linewidths=0.5, cmap='viridis', **kwargs)`
- **Описание**: Строит матрицу корреляций для числовых столбцов с использованием заданного метода корреляции.

#### `plot_numeric_distribution(self, column, kde=True, alpha=0.5, color='g', figsize=(14, 20), **kwargs)`
- **Описание**: Строит график распределения для указанного числового столбца.

#### `smart_report_html(self, file_name)`
- **Описание**: Создает отчет ydata с полной информации о данных.

#### `remove_dublicates(self, **kwargs)`
- **Описание**: Удаляет дубликаты из набора данных.

#### `fill_missing_with_mean(self, column, accuracy=0)`
- **Описание**: Заполняет пропуски в указанном столбце средним значением, округленным до указанной точности.

#### `plot_multiple_numeric_distributions(self, numeric_columns, nrows=1, ncols=1, color='g', alpha=0.5, kde=True, figsize=(14, 20), **kwargs)`
- **Описание**: Строит графики распределений для нескольких числовых столбцов.

#### `plot_categorical_distributions(self, columns, nrows=1, ncols=1, color='g', alpha=0.5, figsize=(14, 20), **kwargs)`
- **Описание**: Строит распределение категориальных признаков для указанных столбцов.

#### `split_train_val_test(self, target_col, train_size=0.3, val_size=0.1)`
- **Описание**: Разделяет набор данных на обучающую, валидационную и тестовую выборки.

#### `fit_lgbm(self, **kwargs)`
- **Описание**: Обучает классификатор LightGBM на обучающем наборе данных.

#### `evaluate_model(self)`
- **Описание**: Оценивает модель на обучающей, валидационной и тестовой выборках, строя ROC-кривую и матрицу ошибок.

#### `shap_analysis(self, max_display=20)`
- **Описание**: Выполняет анализ SHAP для определения важности признаков и отображает результаты.

#### `remove_low_shap_features(self, threshold=0.2)`
- **Описание**: Удаляет признаки с SHAP-важностью ниже указанного порога.

#### `plot_feature_selection_rfecv(self, step=1, cv=5, scoring='recall', **kwargs)`
- **Описание**: Строит результаты выбора признаков с помощью RFECV на основе показателей кросс-валидации.

#### `remove_features_rfe(self, step=1, n_features_to_select=6, **kwargs)`
- **Описание**: Удаляет признаки с помощью рекурсивного исключения признаков (RFE).

#### `PSI(self)`
- **Описание**: Проводит анализ индекса стабильности популяции (PSI) для оценки стабильности признаков.

#### `grid_fit(self, param_grid, scoring='recall', cv=None, **kwargs)`
- **Описание**: Проводит поиск оптимальных гиперпараметров с помощью кросс-валидации и `GridSearchCV`.

#### `evaluate_grid_search_model(self)`
- **Описание**: Оценивает настроенную модель по результатам `GridSearchCV` на обучающей, валидационной и тестовой выборках.

#### `save_grid_model_joblib(self, name='grid_model.joblib', **kwargs)`
- **Описание**: Сохраняет настроенную модель в файл с использованием `joblib`.

#### `save_grid_model_pickle(self, name='grid_model.pkl', **kwargs)`
- **Описание**: Сохраняет настроенную модель в файл с использованием `pickle`.

### Лицензия
Проект распространяется под лицензией MIT.